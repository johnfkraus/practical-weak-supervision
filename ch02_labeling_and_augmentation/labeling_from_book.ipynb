{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [5, 21, 1, 29, 32, 37, 10, 20, 10, 26, 2, 37, 34, 11, 22, 36, 12, 20, 31, 25]\n",
    "df = pd.DataFrame(data, columns=[\"Number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NON_PRIME = 0\n",
    "PRIME = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function()\n",
    "def is_even(record):\n",
    "    if record[\"Number\"] % 2 == 0:\n",
    "        return NON_PRIME\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def is_odd(record):\n",
    "    if record[\"Number\"] % 2 == 1:\n",
    "        return ABSTAIN\n",
    "    else:\n",
    "        return NON_PRIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def is_two(record):\n",
    "    if record[\"Number\"] == 2:\n",
    "        return PRIME\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The list of \"known\" prime numbers\n",
    "known_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n",
    "@labeling_function()\n",
    "def is_known_prime(record):\n",
    "    if record[\"Number\"] in known_primes:\n",
    "        return PRIME\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 10911.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "lfs = [\n",
    "    is_odd,\n",
    "    is_even,\n",
    "    is_two,\n",
    "    is_known_prime\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_odd</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_even</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_two</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_known_prime</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts\n",
       "is_odd          0      [0]      0.55      0.55       0.05\n",
       "is_even         1      [0]      0.55      0.55       0.05\n",
       "is_two          2      [1]      0.05      0.05       0.05\n",
       "is_known_prime  3      [1]      0.20      0.05       0.05"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 2480.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_odd</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_even</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_two</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_known_prime</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "is_odd          0      [0]       0.6       0.6        0.2        2          1   \n",
       "is_even         1      [0]       0.6       0.6        0.2        2          1   \n",
       "is_two          2      [1]       0.2       0.2        0.2        1          0   \n",
       "is_known_prime  3      [1]       0.6       0.2        0.2        3          0   \n",
       "\n",
       "                Emp. Acc.  \n",
       "is_odd           0.666667  \n",
       "is_even          0.666667  \n",
       "is_two           1.000000  \n",
       "is_known_prime   1.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a validation set, and create a DataFrame\n",
    "validation = [22, 11, 7, 2, 32]\n",
    "df_val = pd.DataFrame(validation, columns=[\"Number\"])\n",
    "# gather the ground truth labels\n",
    "true_labels = np.array([0, 1, 1, 1, 0])\n",
    "# apply the labels\n",
    "L_valid = applier.apply(df_val)\n",
    "# analyze the labelers and get the summary df\n",
    "LFAnalysis(L_valid, lfs).lf_summary(true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_even</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  is_odd  is_even  is_two  is_known_prime\n",
       "0      22       0        0      -1              -1\n",
       "1      11      -1       -1      -1               1\n",
       "2       7      -1       -1      -1               1\n",
       "3       2       0        0       1               1\n",
       "4      32       0        0      -1              -1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.DataFrame(validation, columns=[\"Number\"])\n",
    "df_val[\"is_odd\"] = df_val.apply(is_odd, axis=1)\n",
    "df_val[\"is_even\"] = df_val.apply(is_even, axis=1)\n",
    "df_val[\"is_two\"] = df_val.apply(is_two, axis=1)\n",
    "df_val[\"is_known_prime\"] = df_val.apply(is_known_prime, axis=1)\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/200 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.701]\n",
      "INFO:root:[10 epochs]: TRAIN:[loss=0.208]\n",
      "  6%|▌         | 11/200 [00:00<00:01, 102.77epoch/s]INFO:root:[20 epochs]: TRAIN:[loss=0.065]\n",
      "INFO:root:[30 epochs]: TRAIN:[loss=0.025]\n",
      "INFO:root:[40 epochs]: TRAIN:[loss=0.018]\n",
      "INFO:root:[50 epochs]: TRAIN:[loss=0.007]\n",
      "INFO:root:[60 epochs]: TRAIN:[loss=0.005]\n",
      "INFO:root:[70 epochs]: TRAIN:[loss=0.004]\n",
      "INFO:root:[80 epochs]: TRAIN:[loss=0.004]\n",
      " 40%|████      | 81/200 [00:00<00:00, 442.53epoch/s]INFO:root:[90 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[110 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[120 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[130 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[140 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[150 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[160 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[170 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[180 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[190 epochs]: TRAIN:[loss=0.003]\n",
      "100%|██████████| 200/200 [00:00<00:00, 640.31epoch/s]\n",
      "INFO:root:Finished Training\n",
      "100%|██████████| 5/5 [00:00<00:00, 3644.69it/s]\n"
     ]
    }
   ],
   "source": [
    "label_model = LabelModel()\n",
    "label_model.fit(L_train=L_train, n_epochs=200, seed=100)\n",
    "preds_train_label = label_model.predict(L=L_train)\n",
    "preds_valid_label = label_model.predict(L=L_valid)\n",
    "L_valid = applier.apply(df_val)\n",
    "LFAnalysis(L_valid, lfs).lf_summary()\n",
    "preds_train_labelingModel = label_model.predict(L=L_train)\n",
    "preds_valid_labelingModel = label_model.predict(L=L_valid)\n",
    "df[\"preds_labelingModel\"] = preds_train_labelingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_micro': 0.8000000000000002} {'accuracy': 0.8} {'recall': 0.6666666666666666} {'precision': 1.0}\n"
     ]
    }
   ],
   "source": [
    "f1_micro = label_model.score(L_valid, true_labels, metrics=[\"f1_micro\"])\n",
    "accuracy = label_model.score(L_valid, true_labels, metrics=[\"accuracy\"])\n",
    "recall = label_model.score(L_valid, true_labels, metrics=[\"recall\"])\n",
    "precision = label_model.score(L_valid, true_labels, metrics=[\"precision\"])\n",
    "print(\"{} {} {} {}\".format(f1_micro, accuracy, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_micro': 0.8000000000000002} {'accuracy': 0.8} {'recall': 0.6666666666666666} {'precision': 1.0}\n"
     ]
    }
   ],
   "source": [
    "f1_micro = label_model.score(L_valid, true_labels, metrics=[\"f1_micro\"])\n",
    "accuracy = label_model.score(L_valid, true_labels, metrics=[\"accuracy\"])\n",
    "recall = label_model.score(L_valid, true_labels, metrics=[\"recall\"])\n",
    "\n",
    "precision = label_model.score(L_valid, true_labels, metrics=[\"precision\"])\n",
    "print(\"{} {} {} {}\".format(f1_micro, accuracy, recall, precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('prac-weak')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3239d9b19dc71823afce0461a5421d11a9d24253957a55b30a6bf76803c2fa56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
