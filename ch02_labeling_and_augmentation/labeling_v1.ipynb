{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling Prime Numbers with Snorkel\n",
    "\n",
    "This notebook is adapted from Chapter 2 of [Practical Weak Supervision](https://learning.oreilly.com/library/view/practical-weak-supervision/9781492077053/).\n",
    "\n",
    "The steps applied below for demonstrating Snorkel data labeling are:\n",
    "\n",
    "1. Create a small data set and smaller validation set.  Each data point is an integer.\n",
    "2. Use labeling functions to create a list of labels for each data point.  The labels for the small data set are represented in a label matrix (named \"L\" or \"Lxxx\").\n",
    "3. Use a (generative) model to resolve the list of labels for each data point to a single label.\n",
    "4. Evaluate the accuracy of the (generative) model by applying it to the validation set and comparing predicted labels to ground truth.  \n",
    "5. If the generative model is satisfactory, use its predicted labels for the small data set to train a logistic regression model (or perhaps some other model you prefer).\n",
    "6. Use the logistic regression model to label a large data set.\n",
    "7. Assess the accuracy of the large data set labels by comparing the labels to ground truth.  Ground truth is readily determined in the case of prime numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john.kraus/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "import is_it_prime   # custom code for prime number operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a small example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =    [5, 21, 1, 29, 32, 37, 10, 20, 10, 26, 2, 37, 34, 11, 22, 36, 12, 20, 31, 25]\n",
    "df = pd.DataFrame(data, columns=['Number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a small validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth array for the validation set. \n",
    "\n",
    "22 -> not prime [0]<br>\n",
    "11 -> prime [1]<br>\n",
    "7 -> prime [1]<br>\n",
    "2 -> prime [1]<br>\n",
    "32 -> not prime [0]<br>\n",
    "etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import is_it_prime  # custom code\n",
    "#  the book example used [22, 11, 7, 2, 32], we use:\n",
    "validation_data = [22, 11, 7, 2, 32, 101, 102]  # a list\n",
    "validation_true_labels = is_it_prime.array_map(validation_data)  # an ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.DataFrame(validation_data, columns=['Number'])\n",
    "df_tl = pd.DataFrame(validation_true_labels, columns=['true_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NON_PRIME = 0\n",
    "PRIME = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if odd, abstain else non-prime.\n",
    "@labeling_function()\n",
    "def is_odd(record):\n",
    "    if record[\"Number\"]%2 == 1:\n",
    "        return ABSTAIN\n",
    "    else:\n",
    "        return NON_PRIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def is_two(record):\n",
    "    if record[\"Number\"] == 2:\n",
    "        return PRIME\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def is_known_prime(record):\n",
    "    # known_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]  # original list from book code\n",
    "    known_primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 101]\n",
    "    if record[\"Number\"] in known_primes:\n",
    "        return PRIME\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if > 3 and not evenly divisible by 3 ABSTAIN else NON_PRIME; so this kind of combines two function, unlike the above rules, where we apply rules for odd numbers and 2 in separate functions.  Also, 3 is a known prime in the known primes labeling function above.  Is this a problem (\"multicollinearity\" or something)?. \n",
    "@labeling_function()\n",
    "def gt3_ndb_3(record):\n",
    "    if record[\"Number\"]>3 and record[\"Number\"]%3 == 0:\n",
    "        return NON_PRIME\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating: Polarity, Coverage, Overlaps and Conflicts for the labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of the labeling functions to be applied\n",
    "lfs = [\n",
    "        is_odd,\n",
    "        is_two,\n",
    "        is_known_prime,\n",
    "        # gt3_ndb_3\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 4514.62it/s]\n"
     ]
    }
   ],
   "source": [
    "def apply_labeling_functions(lfs_, df_):\n",
    "    \"\"\" Returns an ndarray with a column for each labeling function and a row for each data point\n",
    "    Args:\n",
    "        lfs_ (list): A list of labeling functions.\n",
    "        df_ (Pandas DataFrame): A dataframe having one column labeled Number, a row for each data point, and an index starting with zero.\n",
    "    \"\"\"\n",
    "    applier = PandasLFApplier(lfs=lfs_)\n",
    "    # print(df_.shape)\n",
    "    if df_.shape[1] != 1:\n",
    "        print(\"check shape?\")\n",
    "    # print(df_.head())\n",
    "    L_label_matrix = applier.apply(df=df_)\n",
    "    return L_label_matrix\n",
    "\n",
    "# generate a label matrix for training the generative model, with the matrix having shape (m=# of labeling functions, n=number of data points)\n",
    "L_train = apply_labeling_functions(lfs, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the labeling functions to the dataset, for illustration of calculating the above metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  is_odd  is_two  is_known_prime\n",
       "0        5      -1      -1               1\n",
       "1       21      -1      -1              -1\n",
       "2        1      -1      -1              -1\n",
       "3       29      -1      -1               1\n",
       "4       32       0      -1              -1\n",
       "5       37      -1      -1              -1\n",
       "6       10       0      -1              -1\n",
       "7       20       0      -1              -1\n",
       "8       10       0      -1              -1\n",
       "9       26       0      -1              -1\n",
       "10       2       0       1               1\n",
       "11      37      -1      -1              -1\n",
       "12      34       0      -1              -1\n",
       "13      11      -1      -1               1\n",
       "14      22       0      -1              -1\n",
       "15      36       0      -1              -1\n",
       "16      12       0      -1              -1\n",
       "17      20       0      -1              -1\n",
       "18      31      -1      -1              -1\n",
       "19      25      -1      -1              -1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show Number and columns of \"noisy\" labels.\n",
    "df[\"is_odd\"] = df.apply(is_odd, axis=1)\n",
    "df[\"is_two\"] = df.apply(is_two, axis=1)\n",
    "df[\"is_known_prime\"] = df.apply(is_known_prime, axis=1)\n",
    "if gt3_ndb_3 in lfs:\n",
    "    df[\"gt3_ndb_3\"] = df.apply(gt3_ndb_3, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polarity (How many distinct labels do each labeling function emit, not counting abstentions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_polarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Coverage (what is the proportion of points to which each labeling function applies a label, as opposed to abstaining?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number            1.00\n",
      "is_odd            0.55\n",
      "is_two            0.05\n",
      "is_known_prime    0.20\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[df!= -1].count()/df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlaps (proportion of data points labeled differently by two LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.05, 0.05])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_overlaps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conflicts  (proportion of data points labeled differently by two LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.05, 0.05])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_conflicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating: Correct, Incorrect and Empirical Accuracy on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 5247.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_odd</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_two</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_known_prime</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "is_odd          0      [0]  0.571429  0.142857   0.142857        3          1   \n",
       "is_two          1      [1]  0.142857  0.142857   0.142857        1          0   \n",
       "is_known_prime  2      [1]  0.571429  0.142857   0.142857        4          0   \n",
       "\n",
       "                Emp. Acc.  \n",
       "is_odd               0.75  \n",
       "is_two               1.00  \n",
       "is_known_prime       1.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the labeling functions to the validation set; returns a label from each L.F. for each data point. \n",
    "L_valid = apply_labeling_functions(lfs,  pd.DataFrame(validation_data, columns=['Number']))\n",
    "\n",
    "LFAnalysis(L_valid, lfs).lf_summary(validation_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the labeling functions to the validation set, just for illustration of calculating the above metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  is_odd  is_two  is_known_prime  ground_truth\n",
       "0      22       0      -1              -1             0\n",
       "1      11      -1      -1               1             1\n",
       "2       7      -1      -1               1             1\n",
       "3       2       0       1               1             1\n",
       "4      32       0      -1              -1             0\n",
       "5     101      -1      -1               1             1\n",
       "6     102       0      -1              -1             0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.DataFrame(validation_data, columns=['Number'])\n",
    "df_val[\"is_odd\"] = df_val.apply(is_odd, axis=1)\n",
    "df_val[\"is_two\"] = df_val.apply(is_two, axis=1)\n",
    "df_val[\"is_known_prime\"] = df_val.apply(is_known_prime, axis=1)\n",
    "df_val[\"ground_truth\"] = validation_true_labels\n",
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Voter to determine a single predicted label for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "      <th>preds_train_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  is_odd  is_two  is_known_prime  preds_train_random\n",
       "0        5      -1      -1               1                   0\n",
       "1       21      -1      -1              -1                   1\n",
       "2        1      -1      -1              -1                   1\n",
       "3       29      -1      -1               1                   0\n",
       "4       32       0      -1              -1                   1\n",
       "5       37      -1      -1              -1                   1\n",
       "6       10       0      -1              -1                   1\n",
       "7       20       0      -1              -1                   0\n",
       "8       10       0      -1              -1                   0\n",
       "9       26       0      -1              -1                   1\n",
       "10       2       0       1               1                   1\n",
       "11      37      -1      -1              -1                   0\n",
       "12      34       0      -1              -1                   1\n",
       "13      11      -1      -1               1                   1\n",
       "14      22       0      -1              -1                   0\n",
       "15      36       0      -1              -1                   1\n",
       "16      12       0      -1              -1                   1\n",
       "17      20       0      -1              -1                   1\n",
       "18      31      -1      -1              -1                   1\n",
       "19      25      -1      -1              -1                   1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.model import RandomVoter\n",
    "random_model = RandomVoter()\n",
    "preds_train_random = random_model.predict(L=L_train, tie_break_policy='abstain')\n",
    "preds_valid_random = random_model.predict(L=L_valid)\n",
    "df[\"preds_train_random\"] = preds_train_random\n",
    "#df[df[\"Number\"] == 2]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the accuracy of the RandomVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5714285714285714, 'coverage': 1.0, 'precision': 0.6666666666666666, 'recall': 0.5, 'f1': 0.5714285714285715, 'f1_micro': 0.5714285714285714, 'f1_macro': 0.5714285714285715, 'matthews_corrcoef': 0.16666666666666666, 'roc_auc': 0.6666666666666667}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<snorkel.labeling.model.baselines.RandomVoter object at 0x7fb3c09ebd00>\n",
      "[0 1 1 1 1 0 0]\n",
      "[0 1 1 1 0 1 0]\n",
      "<snorkel.labeling.model.baselines.RandomVoter object at 0x7fb3c09ebd00>\n",
      "[0 1 1 1 1 0 0]\n",
      "[0 1 1 1 0 1 0]\n",
      "accuracy from model score =  {'accuracy': 0.7142857142857143}\n",
      "preds =  [0 1 1 1 1 0 0]\n",
      "truth =  [0 1 1 1 0 1 0]\n",
      "calculate the accuracy =  0.7142857142857143\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# for reference: METRICS = { \n",
    "#      \"accuracy\": Metric(skmetrics.accuracy_score), \n",
    "#      \"coverage\": Metric(_coverage_score, [\"preds\"]), \n",
    "#      \"precision\": Metric(skmetrics.precision_score), \n",
    "#      \"recall\": Metric(skmetrics.recall_score), \n",
    "#      \"f1\": Metric(_f1_score, [\"golds\", \"preds\"]), \n",
    "#      \"f1_micro\": Metric(_f1_micro_score, [\"golds\", \"preds\"]), \n",
    "#      \"f1_macro\": Metric(_f1_macro_score, [\"golds\", \"preds\"]), \n",
    "#      \"fbeta\": Metric(skmetrics.fbeta_score), \n",
    "#      \"matthews_corrcoef\": Metric(skmetrics.matthews_corrcoef), \n",
    "#      \"roc_auc\": Metric(_roc_auc_score, [\"golds\", \"probs\"]), \n",
    "#  } \n",
    "\n",
    "# metrics_list = ['accuracy', 'coverage', 'precision', 'recall', 'f1', 'f1_micro', 'f1_macro', 'matthews_corrcoef', 'roc_auc']\n",
    "# metrics = random_model.score(preds_valid_random, validation_true_labels, metrics_list)  \n",
    "# accuracy_random_model = metrics[\"accuracy\"]\n",
    "# # df_valid_metrics[\"accur_rand_mod\"] = np.ndarray(int(accuracy_random_model))\n",
    "# metrics\n",
    "\n",
    "def get_metrics(model, predictions, truth):\n",
    "    metrics_list = ['accuracy', 'coverage', 'precision', 'recall', 'f1', 'f1_micro', 'f1_macro', 'matthews_corrcoef', 'roc_auc']\n",
    "    metrics = model.score(predictions, truth, metrics_list)\n",
    "    return metrics\n",
    "\n",
    "metrics = get_metrics(random_model, preds_valid_random, validation_true_labels)\n",
    "print(metrics)\n",
    "\n",
    "\n",
    "def get_accuracy_from_model_score(model, predictions, truth):\n",
    "    # metrics_list = ['accuracy', 'coverage', 'precision', 'recall', 'f1', 'f1_micro', 'f1_macro', 'matthews_corrcoef', 'roc_auc']\n",
    "    print(model)\n",
    "    print(predictions)\n",
    "    print(truth)\n",
    "    acc = model.score(predictions, truth, metrics=['accuracy'])\n",
    "    return acc\n",
    "\n",
    "accuracy = get_accuracy_from_model_score(random_model, preds_valid_random, validation_true_labels)\n",
    "accuracy = get_accuracy_from_model_score(random_model, preds_valid_random, validation_true_labels)\n",
    "print('accuracy from model score = ', accuracy)\n",
    "\n",
    "def calculate_the_accuracy(preds, truth):\n",
    "    print(\"preds = \", preds)\n",
    "    print(\"truth = \", truth)\n",
    "    return (preds == truth).mean()\n",
    "\n",
    "\n",
    "print('calculate the accuracy = ', calculate_the_accuracy(preds_valid_random, validation_true_labels))\n",
    "\n",
    "print((preds_valid_random == validation_true_labels).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MajorityClassVoter\n",
    "\n",
    "Predicts probabilities using just the majority class.  Assign majority class vote to each datapoint. In case of multiple majority classes, assign equal probabilities among them.  For example, if balance=[0.7,0.3], then all the data points will be labeled 0.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityClassVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "      <th>preds_train_random</th>\n",
       "      <th>majorityClass_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  is_odd  is_two  is_known_prime  preds_train_random  \\\n",
       "10       2       0       1               1                   1   \n",
       "\n",
       "    majorityClass_pred  \n",
       "10                   0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_class_model = MajorityClassVoter()\n",
    "majority_class_model.fit(balance=np.array([0.7, 0.3]))\n",
    "majority_class_train_preds = majority_class_model.predict(L=L_train)\n",
    "majority_class_val_preds = majority_class_model.predict(L=L_valid)\n",
    "df[\"majorityClass_pred\"] = majority_class_train_preds\n",
    "df[df[\"Number\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "/Users/john.kraus/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.42857142857142855,\n",
       " 'coverage': 1.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'f1': 0.0,\n",
       " 'f1_micro': 0.42857142857142855,\n",
       " 'f1_macro': 0.3,\n",
       " 'matthews_corrcoef': 0.0,\n",
       " 'roc_auc': 0.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics = majority_class_model.score(majority_class_val_preds, validation_true_labels, metrics=['accuracy'])\n",
    "# accuracy_majority_class_model = metrics[\"accuracy\"]\n",
    "# metrics\n",
    "\n",
    "\n",
    "val_metrics = get_metrics(majority_class_model, majority_class_val_preds, validation_true_labels)\n",
    "val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "/Users/john.kraus/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.42857142857142855,\n",
       " 'coverage': 1.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'f1': 0.0,\n",
       " 'f1_micro': 0.42857142857142855,\n",
       " 'f1_macro': 0.3,\n",
       " 'matthews_corrcoef': 0.0,\n",
       " 'roc_auc': 0.5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = get_metrics(majority_class_model, majority_class_val_preds, validation_true_labels)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "/Users/john.kraus/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "/Users/john.kraus/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if get_metrics(majority_class_model, majority_class_val_preds, validation_true_labels) != get_metrics(majority_class_model, majority_class_val_preds, validation_true_labels):\n",
    "    print(\"metrics not equal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MajorityLabelVoter to determine the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_model = MajorityLabelVoter()\n",
    "preds_train_majority_label = majority_model.predict(L=L_train)\n",
    "preds_valid_majority_label = majority_model.predict(L=L_valid)\n",
    "df[\"majorityLabel_pred\"] = preds_train_majority_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "      <th>preds_train_random</th>\n",
       "      <th>majorityClass_pred</th>\n",
       "      <th>majorityLabel_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  is_odd  is_two  is_known_prime  preds_train_random  \\\n",
       "10       2       0       1               1                   1   \n",
       "\n",
       "    majorityClass_pred  majorityLabel_pred  \n",
       "10                   0                   1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Number\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# doesn't work:\n",
    "# metrics2 = majority_model.score(preds_valid_majority, validation_true_labels, metrics=['accuracy'])\n",
    "# metrics2\n",
    "val_accuracy_maj_label_voter_model = (preds_valid_majority_label == validation_true_labels).mean()\n",
    "print(val_accuracy_maj_label_voter_model)\n",
    "\n",
    "def get_accuracy(label_preds_ndarray, true_labels_ndarray):\n",
    "    return (preds_valid_majority_label == validation_true_labels).mean()\n",
    "\n",
    "print(get_accuracy(preds_valid_majority_label, validation_true_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "      <th>pred_maj_label</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  is_odd  is_two  is_known_prime  pred_maj_label  ground_truth\n",
       "0      22       0      -1              -1               0             0\n",
       "1      11      -1      -1               1               1             1\n",
       "2       7      -1      -1               1               1             1\n",
       "3       2       0       1               1               1             1\n",
       "4      32       0      -1              -1               0             0\n",
       "5     101      -1      -1               1               1             1\n",
       "6     102       0      -1              -1               0             0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.DataFrame(validation_data, columns=['Number'])\n",
    "df_val[\"is_odd\"] = df_val.apply(is_odd, axis=1)\n",
    "df_val[\"is_two\"] = df_val.apply(is_two, axis=1)\n",
    "df_val[\"is_known_prime\"] = df_val.apply(is_known_prime, axis=1)\n",
    "if gt3_ndb_3 in lfs:\n",
    "    df_val[\"gt3_ndb_3\"] = df_val.apply(gt3_ndb_3, axis=1)\n",
    "df_val[\"pred_maj_label\"] = preds_valid_majority_label\n",
    "df_val[\"ground_truth\"] = validation_true_labels\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round(majority_model.get_weights(), 2)\n",
    "# 'MajorityLabelVoter' object has no attribute 'get_weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LabelingModel to determine the label\n",
    "\n",
    "Documentation: https://snorkel.readthedocs.io/en/v0.9.3/packages/_autosummary/labeling/snorkel.labeling.LabelModel.html\n",
    "\n",
    "A model for learning the LF accuracies and combining their output labels.\n",
    "\n",
    "This class learns a model of the labeling functions’ conditional probabilities of outputting the true (unobserved) label Y, P(lf | Y), and uses this learned model to re-weight and combine their output labels.\n",
    "\n",
    "This class is based on the approach in [Training Complex Models with Multi-Task Weak Supervision](https://arxiv.org/abs/1810.02840), published in AAAI‘19. In this approach, we compute the inverse generalized covariance matrix of the junction tree of a given LF dependency graph, and perform a matrix completion-style approach with respect to these empirical statistics. The result is an estimate of the conditional LF probabilities, P(lf | Y), which are then set as the parameters of the label model used to re-weight and combine the labels output by the LFs.\n",
    "\n",
    "Currently this class uses a conditionally independent label model, in which the LFs are assumed to be conditionally independent given Y.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 1190.89epoch/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 5208.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_odd</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_two</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_known_prime</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "is_odd          0      [0]  0.571429  0.142857   0.142857        3          1   \n",
       "is_two          1      [1]  0.142857  0.142857   0.142857        1          0   \n",
       "is_known_prime  2      [1]  0.571429  0.142857   0.142857        4          0   \n",
       "\n",
       "                Emp. Acc.  \n",
       "is_odd               0.75  \n",
       "is_two               1.00  \n",
       "is_known_prime       1.00  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model = LabelModel()\n",
    "# no y_train data!\n",
    "label_model.fit(L_train=L_train, n_epochs=200, seed=100)\n",
    "preds_train_label = label_model.predict(L=L_train)\n",
    "\n",
    "L_valid = apply_labeling_functions(lfs, pd.DataFrame(validation_data, columns=['Number']))\n",
    "\n",
    "preds_valid_label = label_model.predict(L=L_valid)\n",
    "\n",
    "# L_valid = applier.apply(df_val)\n",
    "# LFAnalysis(L_valid, lfs).lf_summary()\n",
    "LFAnalysis(L_valid, lfs).lf_summary(validation_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_train_labelingModel = label_model.predict(L=L_train)\n",
    "preds_valid_labelingModel = label_model.predict(L=L_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the weights of the label_model for each classification source (labeling function).  Labeling functions that make more mistakes would be expected to have lower weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"preds_label_model\"] = preds_train_labelingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "      <th>preds_train_random</th>\n",
       "      <th>majorityClass_pred</th>\n",
       "      <th>majorityLabel_pred</th>\n",
       "      <th>preds_label_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  is_odd  is_two  is_known_prime  preds_train_random  \\\n",
       "0        5      -1      -1               1                   0   \n",
       "1       21      -1      -1              -1                   1   \n",
       "2        1      -1      -1              -1                   1   \n",
       "3       29      -1      -1               1                   0   \n",
       "4       32       0      -1              -1                   1   \n",
       "5       37      -1      -1              -1                   1   \n",
       "6       10       0      -1              -1                   1   \n",
       "7       20       0      -1              -1                   0   \n",
       "8       10       0      -1              -1                   0   \n",
       "9       26       0      -1              -1                   1   \n",
       "10       2       0       1               1                   1   \n",
       "11      37      -1      -1              -1                   0   \n",
       "12      34       0      -1              -1                   1   \n",
       "13      11      -1      -1               1                   1   \n",
       "14      22       0      -1              -1                   0   \n",
       "15      36       0      -1              -1                   1   \n",
       "16      12       0      -1              -1                   1   \n",
       "17      20       0      -1              -1                   1   \n",
       "18      31      -1      -1              -1                   1   \n",
       "19      25      -1      -1              -1                   1   \n",
       "\n",
       "    majorityClass_pred  majorityLabel_pred  preds_label_model  \n",
       "0                    0                   1                  1  \n",
       "1                    0                  -1                 -1  \n",
       "2                    0                  -1                 -1  \n",
       "3                    0                   1                  1  \n",
       "4                    0                   0                  0  \n",
       "5                    0                  -1                 -1  \n",
       "6                    0                   0                  0  \n",
       "7                    0                   0                  0  \n",
       "8                    0                   0                  0  \n",
       "9                    0                   0                  0  \n",
       "10                   0                   1                  1  \n",
       "11                   0                  -1                 -1  \n",
       "12                   0                   0                  0  \n",
       "13                   0                   1                  1  \n",
       "14                   0                   0                  0  \n",
       "15                   0                   0                  0  \n",
       "16                   0                   0                  0  \n",
       "17                   0                   0                  0  \n",
       "18                   0                  -1                 -1  \n",
       "19                   0                  -1                 -1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[[\"Number\", \"preds_train_random\", \"majorityClass_pred\", \"majorityLabel_pred\", \"preds_labelingModel\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelModel with class balance\n",
    "\n",
    "    r\"\"\"A model for learning the LF accuracies and combining their output labels.\n",
    "\n",
    "    This class learns a model of the labeling functions' conditional probabilities\n",
    "    of outputting the true (unobserved) label `Y`, `P(\\lf | Y)`, and uses this learned\n",
    "    model to re-weight and combine their output labels.\n",
    "\n",
    "    This class is based on the approach in [Training Complex Models with Multi-Task\n",
    "    Weak Supervision](https://arxiv.org/abs/1810.02840), published in AAAI'19. In this\n",
    "    approach, we compute the inverse generalized covariance matrix of the junction tree\n",
    "    of a given LF dependency graph, and perform a matrix completion-style approach with\n",
    "    respect to these empirical statistics. The result is an estimate of the conditional\n",
    "    LF probabilities, `P(\\lf | Y)`, which are then set as the parameters of the label\n",
    "    model used to re-weight and combine the labels output by the LFs.\n",
    "\n",
    "    Currently this class uses a conditionally independent label model, in which the LFs\n",
    "    are assumed to be conditionally independent given `Y`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> label_model = LabelModel()\n",
    "    >>> label_model = LabelModel(cardinality=3)\n",
    "    >>> label_model = LabelModel(cardinality=3, device='cpu')\n",
    "    >>> label_model = LabelModel(cardinality=3)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cardinality\n",
    "        Number of classes, by default 2\n",
    "    **kwargs\n",
    "        Arguments for changing config defaults\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If config device set to cuda but only cpu is available\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cardinality\n",
    "        Number of classes, by default 2\n",
    "    config\n",
    "        Training configuration\n",
    "    seed\n",
    "        Random seed\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 1310.79epoch/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 5832.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_odd</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_two</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_known_prime</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  \\\n",
       "is_odd          0      [0]  0.571429  0.142857   0.142857        3          1   \n",
       "is_two          1      [1]  0.142857  0.142857   0.142857        1          0   \n",
       "is_known_prime  2      [1]  0.571429  0.142857   0.142857        4          0   \n",
       "\n",
       "                Emp. Acc.  \n",
       "is_odd               0.75  \n",
       "is_two               1.00  \n",
       "is_known_prime       1.00  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7/20 prime numbers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_model_wcb = LabelModel()\n",
    "# no Y_train data!!\n",
    "label_model_wcb.fit(L_train=L_train, n_epochs=200, class_balance = [0.7, 0.3], seed=100)\n",
    "preds_train_label_wcb = label_model_wcb.predict(L=L_train)\n",
    "preds_valid_label_wcb = label_model_wcb.predict(L=L_valid)\n",
    "# L_valid = applier.apply(df_val)\n",
    "\n",
    "L_valid = apply_labeling_functions(lfs, pd.DataFrame(validation_data, columns=['Number']))\n",
    "\n",
    "\n",
    "# LFAnalysis(L_valid, lfs).lf_summary()\n",
    "LFAnalysis(L_valid, lfs).lf_summary(validation_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with class balance\n",
    "# preds_train_labelingModel_wcb = label_model_wcb.predict(L=L_train)\n",
    "df[\"preds_label_model_wcb\"] = preds_train_label_wcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>preds_label_model</th>\n",
       "      <th>preds_label_model_wcb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number  preds_label_model  preds_label_model_wcb\n",
       "0        5                  1                      1\n",
       "1       21                 -1                      0\n",
       "2        1                 -1                      0\n",
       "3       29                  1                      1\n",
       "4       32                  0                      0\n",
       "5       37                 -1                      0\n",
       "6       10                  0                      0\n",
       "7       20                  0                      0\n",
       "8       10                  0                      0\n",
       "9       26                  0                      0\n",
       "10       2                  1                      1\n",
       "11      37                 -1                      0\n",
       "12      34                  0                      0\n",
       "13      11                  1                      1\n",
       "14      22                  0                      0\n",
       "15      36                  0                      0\n",
       "16      12                  0                      0\n",
       "17      20                  0                      0\n",
       "18      31                 -1                      0\n",
       "19      25                 -1                      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Number\", \"preds_label_model\", \"preds_label_model_wcb\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the weights of the label_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94, 0.93, 0.77])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(label_model_wcb.get_weights(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m accuracy_labeling_model_wcbal \u001b[39m=\u001b[39m (preds_valid_label_wcb \u001b[39m==\u001b[39m validation_true_labels)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(accuracy_labeling_model_wcbal)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb#Y115sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m get_metrics(label_model_wcb, preds_valid_label_wcb, validation_true_labels)\n",
      "\u001b[1;32m/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb Cell 60\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(model, predictions, truth)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb#Y115sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_metrics\u001b[39m(model, predictions, truth):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb#Y115sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     metrics_list \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcoverage\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_micro\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmatthews_corrcoef\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb#Y115sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mscore(predictions, truth, metrics_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/john.kraus/workspaces/mysnorkel/practical-weak-supervision/ch02_labeling_and_augmentation/labeling_v1.ipynb#Y115sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/snorkel/labeling/model/label_model.py:510\u001b[0m, in \u001b[0;36mLabelModel.score\u001b[0;34m(self, L, Y, metrics, tie_break_policy)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\n\u001b[1;32m    470\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    471\u001b[0m     L: np\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    474\u001b[0m     tie_break_policy: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabstain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    475\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    476\u001b[0m     \u001b[39m\"\"\"Calculate one or more scores from user-specified and/or user-defined metrics.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39m    {'f1': 0.8}\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(LabelModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mscore(L, Y, metrics, tie_break_policy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/snorkel/labeling/model/base_labeler.py:105\u001b[0m, in \u001b[0;36mBaseLabeler.score\u001b[0;34m(self, L, Y, metrics, tie_break_policy)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m tie_break_policy \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabstain\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    102\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMetrics calculated over data points with non-abstain labels only\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m     )\n\u001b[0;32m--> 105\u001b[0m Y_pred, Y_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    106\u001b[0m     L, return_probs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, tie_break_policy\u001b[39m=\u001b[39;49mtie_break_policy\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    109\u001b[0m scorer \u001b[39m=\u001b[39m Scorer(metrics\u001b[39m=\u001b[39mmetrics)\n\u001b[1;32m    110\u001b[0m results \u001b[39m=\u001b[39m scorer\u001b[39m.\u001b[39mscore(Y, Y_pred, Y_prob)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/snorkel/labeling/model/label_model.py:467\u001b[0m, in \u001b[0;36mLabelModel.predict\u001b[0;34m(self, L, return_probs, tie_break_policy)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m    424\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    425\u001b[0m     L: np\u001b[39m.\u001b[39mndarray,\n\u001b[1;32m    426\u001b[0m     return_probs: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    427\u001b[0m     tie_break_policy: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabstain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    428\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[np\u001b[39m.\u001b[39mndarray, Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray]]:\n\u001b[1;32m    429\u001b[0m     \u001b[39m\"\"\"Return predicted labels, with ties broken according to policy.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[39m    Policies to break ties include:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[39m    array([0, 1, 0])\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(LabelModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mpredict(L, return_probs, tie_break_policy)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/snorkel/labeling/model/base_labeler.py:68\u001b[0m, in \u001b[0;36mBaseLabeler.predict\u001b[0;34m(self, L, return_probs, tie_break_policy)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m     35\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     36\u001b[0m     L: np\u001b[39m.\u001b[39mndarray,\n\u001b[1;32m     37\u001b[0m     return_probs: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     38\u001b[0m     tie_break_policy: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabstain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[np\u001b[39m.\u001b[39mndarray, Tuple[np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray]]:\n\u001b[1;32m     40\u001b[0m     \u001b[39m\"\"\"Return predicted labels, with ties broken according to policy.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[39m    Policies to break ties include:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m        An [n,1] array of integer labels and an [n,k] array of probabilistic labels\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     Y_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(L)\n\u001b[1;32m     69\u001b[0m     Y_p \u001b[39m=\u001b[39m probs_to_preds(Y_probs, tie_break_policy)\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m return_probs:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/snorkel/labeling/model/label_model.py:413\u001b[0m, in \u001b[0;36mLabelModel.predict_proba\u001b[0;34m(self, L)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Return label probabilities P(Y | \\lambda).\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m       [0., 1.]])\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    412\u001b[0m L_shift \u001b[39m=\u001b[39m L \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# convert to {0, 1, ..., k}\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_constants(L_shift)\n\u001b[1;32m    414\u001b[0m L_aug \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_augmented_label_matrix(L_shift)\n\u001b[1;32m    415\u001b[0m mu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/prac-weak/lib/python3.10/site-packages/snorkel/labeling/model/label_model.py:595\u001b[0m, in \u001b[0;36mLabelModel._set_constants\u001b[0;34m(self, L)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_constants\u001b[39m(\u001b[39mself\u001b[39m, L: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39m=\u001b[39m L\u001b[39m.\u001b[39mshape\n\u001b[1;32m    596\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    597\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mL_train should have at least 3 labeling functions\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "accuracy_labeling_model_wcbal = (preds_valid_label_wcb == validation_true_labels).mean()\n",
    "print(accuracy_labeling_model_wcbal)\n",
    "\n",
    "get_metrics(label_model_wcb, preds_valid_label_wcb, validation_true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the actual conditional probability values placed in a matrix with dimensions [number of labeling function, number of labels + 1 (for abstain), number of classes], rounded are as follows:\n",
    "\n",
    "\n",
    "def get_conditional_probs(self) -> np.ndarray:\n",
    "\n",
    "    r\"\"\"Return the estimated conditional probabilities table.\n",
    "\n",
    "    Return the estimated conditional probabilites table cprobs, where cprobs is an\n",
    "    (m, k+1, k)-dim np.ndarray with:\n",
    "\n",
    "        cprobs[i, j, k] = P(\\lf_i = j-1 | Y = k)\n",
    "\n",
    "    where m is the number of LFs, k is the cardinality, and cprobs includes the\n",
    "    conditional abstain probabilities P(\\lf_i = -1 | Y = y).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        An [m, k + 1, k] np.ndarray conditional probabilities table.\n",
    "    \"\"\"\n",
    "```\n",
    "array([\n",
    "labeling function 1  (m=0)\n",
    "       [[\n",
    "(j = 0)        P( lf=1 | Y = 0 ) = 0.114, P( lf=1 | Y=1 ) = 0.98 ],\n",
    "        [0.876, 0.01 ],\n",
    "        [0.01 , 0.01 ]],\n",
    "labeling function 2\n",
    "       [[0.114, 0.98 ],\n",
    "        [0.876, 0.01 ],\n",
    "        [0.01 , 0.01 ]],\n",
    "\n",
    "       [[0.91 , 0.923],\n",
    "        [0.01 , 0.01 ],\n",
    "        [0.08 , 0.067]],\n",
    "\n",
    "       [[0.869, 0.58 ],\n",
    "        [0.01 , 0.01 ],\n",
    "        [0.121, 0.41 ]]])\n",
    "```\n",
    "\n",
    "Looking at the conditional probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.179, 0.699],\n",
       "        [0.811, 0.291],\n",
       "        [0.01 , 0.01 ]],\n",
       "\n",
       "       [[0.957, 0.864],\n",
       "        [0.01 , 0.01 ],\n",
       "        [0.033, 0.126]],\n",
       "\n",
       "       [[0.98 , 0.571],\n",
       "        [0.01 , 0.01 ],\n",
       "        [0.01 , 0.419]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(label_model.get_conditional_probs(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to generate a larger set of labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_odd</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_two</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_known_prime</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts\n",
       "is_odd          0      [0]      0.55      0.05       0.05\n",
       "is_two          1      [1]      0.05      0.05       0.05\n",
       "is_known_prime  2      [1]      0.20      0.05       0.05"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_data_to_be_labeled = range(50, 150)\n",
    "# df_new_data = pd.DataFrame(new_data_to_be_labeled, columns=['Number'])\n",
    "# L_train = applier.apply(df=df_new_data)\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Now that we have a model (using Snorkel LabelModel with class balance) let's label some data.\n",
    "\n",
    "Sources include ML Bookcamp, Snorkel docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out unlabeled data points\n",
    "\n",
    "As we saw earlier, some of the data points in our train set received no labels from any of our LFs. These data points convey no supervision signal and tend to hurt performance, so we filter them out before training using a built-in utility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "# df_train = pd.DataFrame(data, columns=['Number'])\n",
    "# df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "#     X=df_train, y=preds_train_label_wcb, L=L_train\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the Snorkel LabelModel is a set of labels which can be used with most popular libraries for performing supervised learning, such as TensorFlow, Keras, PyTorch, Scikit-Learn, Ludwig, and XGBoost. In the Snorkel spam tutorial we use the well-known library Scikit-Learn. Note that typically, Snorkel is used (and really shines!) with much more complex, training data-hungry models, but we will use Logistic Regression here for simplicity of exposition.  Source: https://www.snorkel.org/use-cases/01-spam-tutorial\n",
    "\n",
    "the LabelModel outputs probabilistic (float) labels. If the classifier we are training accepts target labels as floats, we can train on these labels directly (see describe the properties of this type of “noise-aware” loss in our NeurIPS 2016 paper).\n",
    "\n",
    "If we want to use a library or model that doesn’t accept probabilistic labels (such as Scikit-Learn), we can instead replace each label distribution with the label of the class that has the maximum probability. This can easily be done using the probs_to_preds helper method. We do note, however, that this transformation is lossy, as we no longer have values for our confidence in each label.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snorkel.utils import probs_to_preds\n",
    "# preds_train_filtered = probs_to_preds(probs=probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=1, solver='liblinear')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regr_model = LogisticRegression(solver='liblinear', random_state=1)\n",
    "logistic_regr_model.fit(L_train, preds_train_label_wcb)  # ) y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93715619, 0.06284381],\n",
       "       [0.22348245, 0.77651755],\n",
       "       [0.22348245, 0.77651755],\n",
       "       [0.11021325, 0.88978675],\n",
       "       [0.93715619, 0.06284381],\n",
       "       [0.22348245, 0.77651755],\n",
       "       [0.93715619, 0.06284381]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_pred_probs = logistic_regr_model.predict_proba(L_valid)\n",
    "validation_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>is_odd</th>\n",
       "      <th>is_two</th>\n",
       "      <th>is_known_prime</th>\n",
       "      <th>gt3_ndb_3</th>\n",
       "      <th>pred_majority</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>log_reg_p(1)</th>\n",
       "      <th>log_reg_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.889787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>101</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.062844</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number  is_odd  is_two  is_known_prime  gt3_ndb_3  pred_majority  \\\n",
       "0      22       0      -1              -1         -1              0   \n",
       "1      11      -1      -1               1         -1              1   \n",
       "2       7      -1      -1               1         -1              1   \n",
       "3       2       0       1               1         -1              1   \n",
       "4      32       0      -1              -1         -1              0   \n",
       "5     101      -1      -1               1         -1              1   \n",
       "6     102       0      -1              -1          0              0   \n",
       "\n",
       "   ground_truth  log_reg_p(1)  log_reg_pred  \n",
       "0             0      0.062844             0  \n",
       "1             1      0.776518             1  \n",
       "2             1      0.776518             1  \n",
       "3             1      0.889787             1  \n",
       "4             0      0.062844             0  \n",
       "5             1      0.776518             1  \n",
       "6             0      0.062844             0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.DataFrame(validation_data, columns=['Number'])\n",
    "df_val[\"is_odd\"] = df_val.apply(is_odd, axis=1)\n",
    "# df_val[\"is_even\"] = df_val.apply(is_even, axis=1)\n",
    "df_val[\"is_two\"] = df_val.apply(is_two, axis=1)\n",
    "df_val[\"is_known_prime\"] = df_val.apply(is_known_prime, axis=1)\n",
    "df_val[\"gt3_ndb_3\"] = df_val.apply(gt3_ndb_3, axis=1)\n",
    "df_val[\"pred_majority\"] = preds_valid_majority_label\n",
    "df_val[\"ground_truth\"] = validation_true_labels\n",
    "df_val[\"log_reg_p(1)\"] = validation_pred_probs[:,1]\n",
    "gt_one_half = lambda x: (x > 0.5)\n",
    "df_val[\"log_reg_pred\"] = np.multiply(gt_one_half(df_val[\"log_reg_p(1)\"]),1 )\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_val_log_regr = (df_val[\"log_reg_pred\"] == df_val[\"ground_truth\"]).mean()\n",
    "print(accuracy_val_log_regr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Logistic Regression model to label new, larger data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 31741.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_odd</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_two</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_known_prime</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                j Polarity  Coverage  Overlaps  Conflicts\n",
       "is_odd          0      [0]     0.500     0.005      0.005\n",
       "is_two          1      [1]     0.005     0.005      0.005\n",
       "is_known_prime  2      [1]     0.055     0.005      0.005"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new_data_to_be_labeled = range(50, 150)\n",
    "# df_primes = is_it_prime.make_primes_df(200)\n",
    "# df_new_data_to_be_labeled_by_regr_model = df_primes.loc[50:150, [\"Number\", \"ground_truth\"]].reset_index(drop=True)\n",
    "# df_gr_truth_new_data = df_primes.loc[50:150, [\"ground_truth\"]].reset_index(drop=True)\n",
    "# df_new_data = pd.DataFrame(new_data_to_be_labeled_by_regr_model, columns=['Number'])\n",
    "# df2 = df_new_data_to_be_labeled_by_regr_model[\"Number\"].reset_index(drop=True)\n",
    "# applier2 = PandasLFApplier(lfs=lfs)\n",
    "nums, labels = is_it_prime.make_list_of_num_and_labels(0, 200)\n",
    "df_nums = pd.DataFrame(nums, columns=[\"Number\"])\n",
    "# L = applier2.apply(pd.DataFrame(nums))\n",
    "\n",
    "L = apply_labeling_functions(lfs, df_nums)\n",
    "\n",
    "\n",
    "# LFAnalysis(L, lfs).lf_summary()\n",
    "# L = applier.apply(df=df2)\n",
    "LFAnalysis(L=L, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get probabilistic labels\n",
    "new_data_pred_probs = logistic_regr_model.predict_proba(L)\n",
    "# convert probabilistic labels to zero or one.\n",
    "gt_one_half = lambda x: (x > 0.5)\n",
    "\n",
    "df_nums[\"log_reg_pred\"] = np.multiply(gt_one_half(new_data_pred_probs[:, 1]),1 )\n",
    "\n",
    "df_nums[\"ground_truth\"] = labels\n",
    "acc = (df_nums[\"log_reg_pred\"] == df_nums[\"ground_truth\"] ).mean()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error df shape ==  (35, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>log_reg_pred</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Number  log_reg_pred  ground_truth\n",
       "181     181             0             1\n",
       "191     191             0             1\n",
       "193     193             0             1\n",
       "197     197             0             1\n",
       "199     199             0             1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(df_nums[\"log_reg_pred\"] != df_nums[\"ground_truth\"])\n",
    "print(\"Error df shape == \",df_nums.query(\"log_reg_pred != ground_truth\" ).shape)  # 35/200 are errors\n",
    "df_nums.query(\"log_reg_pred != ground_truth\" ).tail()  # 35/200 are errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "Labeling functions: 3, is_odd, is_two, is_known_prime.\n",
    "Data set: 20 integers\n",
    "Validation: 7 integers\n",
    "\n",
    "Using a logistic regression model with three labeling functions, the Snorkel labeling model with class balance using three labeling functions labeled 20 data points (no ground truth/gold labels). The labeling achieved a 100% accuracy against a validation set of seven data points.\n",
    "\n",
    "A logistic regression model trained using the data set of 20 numbers and the labels from the Snorkel labeling model was then used to label 200 data points (integers 0-200, which includes the original training and validation data points).  Accuracy of labeling by log regr of the 200 data points was 82.5% (based on ground truth).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('prac-weak')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3239d9b19dc71823afce0461a5421d11a9d24253957a55b30a6bf76803c2fa56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
